{"cells":[{"cell_type":"code","execution_count":1,"id":"S0oD_cG3c05K","metadata":{"id":"S0oD_cG3c05K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758457857864,"user_tz":-120,"elapsed":63074,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}},"outputId":"4273e177-47ed-42d5-8a92-40da4f9ccccd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updating pip...\n","Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n","Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-25.2\n","Installing torch and CUDA dependencies...\n","Looking in indexes: https://download.pytorch.org/whl/cu124\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Installing flash-attention and bitsandbytes...\n","Collecting flash-attn\n","  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.8.0+cu126)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n","Building wheels for collected packages: flash-attn\n","\u001b[33m  DEPRECATION: Building 'flash-attn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'flash-attn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n","\u001b[0m  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=256040057 sha256=f25da18657a87fc83dc1bfb8b7751b82246e9db355510226b674fd437c34b5fb\n","  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n","Successfully built flash-attn\n","Installing collected packages: flash-attn\n","Successfully installed flash-attn-2.8.3\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.47.0\n","Installing Hugging Face Transformers and Accelerate...\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n","Collecting transformers\n","  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n","Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.56.1\n","    Uninstalling transformers-4.56.1:\n","      Successfully uninstalled transformers-4.56.1\n","Successfully installed transformers-4.56.2\n","Installing other necessary libraries...\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Collecting anthropic\n","  Downloading anthropic-0.68.0-py3-none-any.whl.metadata (28 kB)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Collecting qwen-vl-utils\n","  Downloading qwen_vl_utils-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.181.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n","Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Collecting av (from qwen-vl-utils)\n","  Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.30.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading anthropic-0.68.0-py3-none-any.whl (325 kB)\n","Downloading qwen_vl_utils-0.0.13-py3-none-any.whl (7.8 kB)\n","Downloading av-15.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m163.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: av, qwen-vl-utils, anthropic\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [anthropic]\n","\u001b[1A\u001b[2KSuccessfully installed anthropic-0.68.0 av-15.1.0 qwen-vl-utils-0.0.13\n","Installation completed.\n"]}],"source":["# @title Library Installation\n","\n","print(\"Updating pip...\")\n","!pip install --upgrade pip\n","\n","print(\"Installing torch and CUDA dependencies...\")\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n","\n","print(\"Installing flash-attention and bitsandbytes...\")\n","!pip install -U flash-attn --no-build-isolation\n","!pip install bitsandbytes --upgrade\n","\n","print(\"Installing Hugging Face Transformers and Accelerate...\")\n","!pip install -U transformers accelerate\n","\n","print(\"Installing other necessary libraries...\")\n","!pip install pandas numpy matplotlib seaborn scikit-learn google-generativeai pillow requests anthropic tensorflow qwen-vl-utils\n","\n","print(\"Installation completed.\")"]},{"cell_type":"code","source":["!pip install transformers==4.48.0"],"metadata":{"id":"aTlkACwIPoRG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758457869434,"user_tz":-120,"elapsed":11559,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}},"outputId":"e32cb913-a69c-4917-be0a-47505d890558"},"id":"aTlkACwIPoRG","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.48.0\n","  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (2.32.4)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.48.0)\n","  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.0) (1.1.9)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.48.0) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.48.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.48.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.48.0) (2025.8.3)\n","Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","\u001b[2K  Attempting uninstall: tokenizers\n","\u001b[2K    Found existing installation: tokenizers 0.22.0\n","\u001b[2K    Uninstalling tokenizers-0.22.0:\n","\u001b[2K      Successfully uninstalled tokenizers-0.22.0\n","\u001b[2K  Attempting uninstall: transformers\n","\u001b[2K    Found existing installation: transformers 4.56.2\n","\u001b[2K    Uninstalling transformers-4.56.2:\n","\u001b[2K      Successfully uninstalled transformers-4.56.2\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers]\n","\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.21.4 transformers-4.48.0\n"]}]},{"cell_type":"code","execution_count":3,"id":"db7f150d-9434-489c-9367-96793e67954a","metadata":{"id":"db7f150d-9434-489c-9367-96793e67954a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758457884485,"user_tz":-120,"elapsed":15048,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}},"outputId":"8ea26107-f575-45cd-f3c1-122f0008d08d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Imports completed.\n"]}],"source":["# @title Library Imports\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from transformers import pipeline\n","\n","from PIL import Image\n","\n","import requests\n","from io import BytesIO\n","import base64\n","import os\n","import torch\n","import anthropic\n","\n","from qwen_vl_utils import process_vision_info\n","\n","from huggingface_hub import login\n","from google.colab import userdata\n","import google.generativeai as genai\n","\n","import re\n","from datetime import datetime\n","import sys\n","import xml.etree.ElementTree as ET\n","import time\n","import json\n","from functools import partial\n","import traceback\n","\n","print(\"Imports completed.\")"]},{"cell_type":"code","execution_count":4,"id":"8EqKbAOsLFHU","metadata":{"id":"8EqKbAOsLFHU","executionInfo":{"status":"ok","timestamp":1758457884524,"user_tz":-120,"elapsed":33,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"outputs":[],"source":["from transformers import  AutoProcessor, AutoModelForCausalLM"]},{"cell_type":"code","execution_count":5,"id":"Y1mvY86nJ0b5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1758457884555,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"},"user_tz":-120},"id":"Y1mvY86nJ0b5","outputId":"f2a87236-ad11-464c-9f7d-23c2b84d9fde"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.48.0\n"]}],"source":["import transformers\n","print(transformers.__version__)"]},{"cell_type":"code","execution_count":6,"id":"vjtXPr43lItW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60836,"status":"ok","timestamp":1758457945393,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"},"user_tz":-120},"id":"vjtXPr43lItW","outputId":"c4413659-8343-42a0-a21c-6fe1bc6c51b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"id":"Jb6Kfp9O9uG8","metadata":{"id":"Jb6Kfp9O9uG8","executionInfo":{"status":"ok","timestamp":1758457945966,"user_tz":-120,"elapsed":561,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"outputs":[],"source":["hf_token = userdata.get('HF_TOKEN')\n","login(token=hf_token)"]},{"cell_type":"code","execution_count":8,"id":"b3e9d3f4-ef77-43e7-8809-7def83e296bf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4977,"status":"ok","timestamp":1758457950976,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"},"user_tz":-120},"id":"b3e9d3f4-ef77-43e7-8809-7def83e296bf","outputId":"170fde11-0405-4f42-cb85-47974597d31f"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                                 url  \\\n","0  http://bafybeicq2uxnud6qz2nlla7utndhtjtrugydx3...   \n","1  http://bafybeiddrvh2jskkihnnlw4i4rs23m43bg56bj...   \n","2  http://bafybeiddup6lnmz2bs3ywtoo7ygy7nuxzppsgq...   \n","3              http://01anjali2001.github.io/netflix   \n","4  http://bafybeidoglaizl6f2nvlkf3n7aek4appfd4goj...   \n","\n","                                        html_content  \\\n","0  0001_bafybeicq2uxnud6qz2nlla7utndhtjtrugydx3td...   \n","1  0002_bafybeiddrvh2jskkihnnlw4i4rs23m43bg56bjpd...   \n","2  0003_bafybeiddup6lnmz2bs3ywtoo7ygy7nuxzppsgqtu...   \n","3      0004_01anjali2001.github.io_netflix/page.html   \n","4  0005_bafybeidoglaizl6f2nvlkf3n7aek4appfd4goj5a...   \n","\n","                                          screenshot  label  \n","0  0001_bafybeicq2uxnud6qz2nlla7utndhtjtrugydx3td...      1  \n","1  0002_bafybeiddrvh2jskkihnnlw4i4rs23m43bg56bjpd...      1  \n","2  0003_bafybeiddup6lnmz2bs3ywtoo7ygy7nuxzppsgqtu...      1  \n","3  0004_01anjali2001.github.io_netflix/screenshot...      1  \n","4  0005_bafybeidoglaizl6f2nvlkf3n7aek4appfd4goj5a...      1  \n"]}],"source":["ruta = '/content/drive/MyDrive/Colab Notebooks/DatasetV1/datasetV1.csv'\n","df = pd.read_csv(ruta, encoding='utf-8')\n","\n","print(df.head())"]},{"cell_type":"code","execution_count":9,"id":"9a6d4dcf-119f-4381-a6ce-200658d7d55d","metadata":{"id":"9a6d4dcf-119f-4381-a6ce-200658d7d55d","executionInfo":{"status":"ok","timestamp":1758457950990,"user_tz":-120,"elapsed":5,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"outputs":[],"source":["df.dropna(inplace=True)"]},{"cell_type":"code","execution_count":10,"id":"14e5f42b-1ff8-4750-a310-0bdc6878de04","metadata":{"id":"14e5f42b-1ff8-4750-a310-0bdc6878de04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758457951022,"user_tz":-120,"elapsed":18,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}},"outputId":"d2c4b1f1-34c4-42f7-c07c-fdff2afc6fb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 4 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   url           1000 non-null   object\n"," 1   html_content  1000 non-null   object\n"," 2   screenshot    1000 non-null   object\n"," 3   label         1000 non-null   int64 \n","dtypes: int64(1), object(3)\n","memory usage: 31.4+ KB\n","None\n","           label\n","count  1000.0000\n","mean      0.8000\n","std       0.4002\n","min       0.0000\n","25%       1.0000\n","50%       1.0000\n","75%       1.0000\n","max       1.0000\n","url             0\n","html_content    0\n","screenshot      0\n","label           0\n","dtype: int64\n","label\n","1    800\n","0    200\n","Name: count, dtype: int64\n"]}],"source":["print(df.info())\n","\n","print(df.describe())\n","\n","print(df.isnull().sum())\n","\n","if 'label' in df.columns:\n","    print(df['label'].value_counts())"]},{"cell_type":"code","execution_count":11,"id":"99840841-90f7-4337-ac39-2f6745f99a32","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":576},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1758457951367,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"},"user_tz":-120},"id":"99840841-90f7-4337-ac39-2f6745f99a32","outputId":"f593fb3e-4f4d-4613-89f5-f4e5c1700c67"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["label_map = {0: 'No Phishing', 1: 'Phishing'}\n","\n","df['label_name'] = df['label'].map(label_map)\n","\n","sns.set(style=\"whitegrid\")\n","\n","plt.figure(figsize=(8, 6))\n","ax = sns.countplot(x='label_name', data=df, hue='label_name', palette={'No Phishing': 'green', 'Phishing': 'red'}, legend=False)\n","\n","plt.title('Phishing vs No Phishing', fontsize=16)\n","plt.xlabel('Website Type', fontsize=14)\n","plt.ylabel('Amount', fontsize=14)\n","\n","for p in ax.patches:\n","    ax.annotate(f'{int(p.get_height())}',\n","                (p.get_x() + p.get_width() / 2., p.get_height()),\n","                ha='center', va='center',\n","                xytext=(0, 10),\n","                textcoords='offset points',\n","                fontsize=12)\n","plt.show()"]},{"cell_type":"code","source":["def prompt_option1_all(html_content: str, screenshot, url):\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determinate if they are fishing or not. You will receive a URL, the HTML of the website and a screenshot.\n","                    Based on that, you have to classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name\n","                    \"\"\"\n","                    f\"URL: {url}\\n\"\n","                    f\"HTML extract: {html_content[:5000]}\"\n","\n","\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"YqjQodDQz3re","executionInfo":{"status":"ok","timestamp":1758457951372,"user_tz":-120,"elapsed":3,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"YqjQodDQz3re","execution_count":12,"outputs":[]},{"cell_type":"code","source":["def prompt_option2_all(html_content: str, screenshot, url):\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determinate if they are fishing or not. You will receive a URL, the HTML of the website and a screenshot.\n","                    Consider:\n","                      1.Identification of the main brand the page is attempting to represent\n","                      2.Suspicious elements (credential fields, urgent calls to action)\n","                      3.Consistency between the identified brand and the displayed domain\n","                      4.Typical visual characteristics of phishing (low-quality logos, typographical errors)\n","                    Based on that, you have to classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name\n","                    \"\"\"\n","                    f\"URL: {url}\\n\"\n","                    f\"HTML extract: {html_content[:5000]}\"\n","\n","\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"abr88mdzz4bn","executionInfo":{"status":"ok","timestamp":1758457951380,"user_tz":-120,"elapsed":2,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"abr88mdzz4bn","execution_count":13,"outputs":[]},{"cell_type":"code","source":["def prompt_option3_all(html_content: str, screenshot, url):\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","              <|image_1|>\\n [Context] You are a professional cybersecurity specialist reviewing websites to determinate if they are fishing or not. You will receive a URL, the HTML of the website and a screenshot.\n","              Follow this process:\n","\n","                  Visual Analysis:\n","                      Identify the main visual elements (logos, colors, structure)\n","                      Look for inconsistencies in the design or low-quality elements\n","                      Detect any fields for entering sensitive data\n","\n","                  Content Analysis:\n","                      Extract the main text and analyze its tone and content\n","                      Look for urgent language or threats\n","                      Verify consistency with the supposed brand\n","\n","                  URL Analysis:\n","                      Examine the domain and compare it with the identified brand\n","                      Look for suspicious characters or typosquatting techniques\n","\n","                  Conclusion:\n","                      Based on that, you have to classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name\n","\n","              \"\"\"\n","                    f\"URL: {url}\\n\"\n","                    f\"HTML extract: {html_content[:5000]}\"\n","\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"ZHajmJIBz4z3","executionInfo":{"status":"ok","timestamp":1758457951386,"user_tz":-120,"elapsed":2,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"ZHajmJIBz4z3","execution_count":14,"outputs":[]},{"cell_type":"code","source":["def prompt_option1_url(html_content: str, screenshot, url):\n","\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                     \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive a URL.\n","                    Based on that, you have to classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                    \"\"\"\n","                    f\"URL: {url}\"\n","\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"n6pRu0E4QH4E","executionInfo":{"status":"ok","timestamp":1758457951393,"user_tz":-120,"elapsed":5,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"n6pRu0E4QH4E","execution_count":15,"outputs":[]},{"cell_type":"code","source":["def prompt_option2_url(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Checklist-augmented Persona prompt for the URL-Only task (LLAVA style).\n","    Ignores html_content and screenshot in the prompt content.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                     \"\"\"\n","                      <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive a URL.\n","                      Consider the following aspects of the URL:\n","                        1. Suspicious domain name (typosquatting, unexpected Top-Level Domain, use of IP addresses)\n","                        2. Subdomain structure and depth\n","                        3. Length and complexity of the URL string\n","                        4. Presence of deceptive elements (e.g., brand names in subdomains or paths)\n","\n","                      Based on that, you have to classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                      \"\"\"\n","                      f\"URL: {url}\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"wmmorQRoQIIP","executionInfo":{"status":"ok","timestamp":1758457951406,"user_tz":-120,"elapsed":3,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"wmmorQRoQIIP","execution_count":16,"outputs":[]},{"cell_type":"code","source":["def prompt_option3_url(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Structured Analysis prompt for the URL-Only task (LLAVA style).\n","    Ignores html_content and screenshot in the prompt content.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n [Context] You are a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive a URL.\n","                    Follow this process to analyze the URL:\n","\n","                        URL Analysis:\n","                            Examine the main domain, looking for signs of typosquatting or unusual Top-Level Domains.\n","                            Analyze the subdomain structure for excessive depth or suspicious names.\n","                            Check if an IP address is used instead of a human-readable domain name.\n","                            Review the path and query string for obfuscation, unusual characters, or deceptive elements.\n","\n","                        Conclusion:\n","                            Based on the URL analysis, classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","\n","                    \"\"\"\n","                    f\"URL: {url}\"\n","\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"KcYqCQVGQIT1","executionInfo":{"status":"ok","timestamp":1758457951415,"user_tz":-120,"elapsed":4,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"KcYqCQVGQIT1","execution_count":17,"outputs":[]},{"cell_type":"code","source":["def prompt_option1_screenshot(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Structured Analysis User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist analyzing website screenshots to detect phishing.\n","                    You will receive a screenshot of a webpage. Classify it as \"Phishing\" or \"Legitimate\" based ONLY on visual elements.\n","                    Respond strictly with one word: 'Phishing' or 'Legitimate'.\n","                    \"\"\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"AofPc0hDRcFM","executionInfo":{"status":"ok","timestamp":1758457951432,"user_tz":-120,"elapsed":15,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"AofPc0hDRcFM","execution_count":18,"outputs":[]},{"cell_type":"code","source":["def prompt_option2_screenshot(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Structured Analysis User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                   \"\"\"\n","                    <|image_1|>\\n As a cybersecurity expert, analyze website screenshots using these visual indicators:\n","                    1. Poor design quality or imitation of legitimate brands\n","                    2. Suspicious login/credit card forms\n","                    3. Urgency warnings or threat messages\n","                    4. Mismatched logos/branding elements\n","                    5. Missing security indicators (padlock, trust seals)\n","                    6. Unprofessional layout or pixelated assets\n","\n","                    Based on this analysis, classify the website and respond strictly with one word: 'Phishing' or 'Legitimate'\n","                  \"\"\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"QbnLIFmARcNW","executionInfo":{"status":"ok","timestamp":1758457951438,"user_tz":-120,"elapsed":3,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"QbnLIFmARcNW","execution_count":19,"outputs":[]},{"cell_type":"code","source":["def prompt_option3_screenshot(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Structured Analysis User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                <|image_1|>\\n [Context] You are a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive a screenshot of a webpage.\n","                Follow this process to analyze the screenshot:\n","\n","                    Screenshot Analysis:\n","                        1. Brand Consistency: Check logos, colors, and typography\n","                        2. Form Analysis: Identify input fields and their context\n","                        3. Security Indicators: Verify padlock icons, SSL cues\n","                        4. Content Quality: Assess language errors and image quality\n","                        5. Urgency Cues: Detect warnings or time-sensitive demands\n","\n","                    Conclusion:\n","                        Based on the screenshot analysis, classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                \"\"\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"5zLamn_hRcVm","executionInfo":{"status":"ok","timestamp":1758457951487,"user_tz":-120,"elapsed":36,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"5zLamn_hRcVm","execution_count":20,"outputs":[]},{"cell_type":"code","source":["def prompt_option1_html(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Zero-shot User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive HTML content.\n","                    Based on the HTML analysis, classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                    \"\"\"\n","                    f\"HTML: {html_content[:5000]}\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"B1oFzWZoRcjK","executionInfo":{"status":"ok","timestamp":1758457951538,"user_tz":-120,"elapsed":36,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"B1oFzWZoRcjK","execution_count":21,"outputs":[]},{"cell_type":"code","source":["def prompt_option2_html(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Checklist-augmented User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n Act as a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive HTML content.\n","                    Consider the following aspects of the HTML:\n","                        1. Suspicious form fields (password/credit card inputs)\n","                        2. Poor design quality or imitation of legitimate brands\n","                        3. Urgency-creating language or threats\n","                        4. Mismatched links (href vs displayed text)\n","                        5. Lack of legitimate contact information\n","                        6. Suspicious scripts or iframes\n","\n","                    Based on this analysis, classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                    \"\"\"\n","                    f\"HTML: {html_content[:5000]}\"\n","        }\n","    ]\n","    return prompt\n"],"metadata":{"id":"xAuR-7eWRcrS","executionInfo":{"status":"ok","timestamp":1758457951564,"user_tz":-120,"elapsed":9,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"xAuR-7eWRcrS","execution_count":22,"outputs":[]},{"cell_type":"code","source":["def prompt_option3_html(html_content: str, screenshot, url):\n","    \"\"\"\n","    Constructs the Structured Analysis User prompt for the HTML-Only task.\n","    Ignores screenshot and url.\n","    \"\"\"\n","    prompt = [\n","        {\n","            \"role\": \"user\",\n","            \"content\":\n","                    \"\"\"\n","                    <|image_1|>\\n [Context] You are a professional cybersecurity specialist reviewing websites to determine if they are phishing or not. You will receive HTML content.\n","                    Follow this process to analyze the HTML:\n","\n","                        HTML Analysis:\n","                            1. Examine the forms for sensitive data collection\n","                            2. Check for brand impersonation in logos/text\n","                            3. Analyze the quality of content and design\n","                            4. Verify link consistency (displayed vs actual URLs)\n","                            5. Look for suspicious scripts or external resources\n","                            6. Check for presence/absence of security indicators\n","\n","                        Conclusion:\n","                            Based on the HTML analysis, classify the website as \"Phishing\" or \"Legitimate\". Just respond with the class name.\n","                    \"\"\"\n","                    f\"HTML: {html_content[:5000]}\"\n","        }\n","    ]\n","    return prompt"],"metadata":{"id":"DjTSJpyDRduX","executionInfo":{"status":"ok","timestamp":1758457951589,"user_tz":-120,"elapsed":21,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"DjTSJpyDRduX","execution_count":23,"outputs":[]},{"cell_type":"code","source":["def _load_row_data(row: pd.Series, base_path: str):\n","    \"\"\"\n","    Loads and prepares HTML content and a screenshot from a given row of a DataFrame.\n","\n","    Args:\n","        row (pd.Series): A row from a DataFrame containing 'html_content' and 'screenshot' file paths.\n","        base_path (str): The base directory where the files are located.\n","\n","    Returns:\n","        tuple: A tuple containing the HTML content (str) and the prepared screenshot (PIL.Image).\n","    \"\"\"\n","    html_path = os.path.join(base_path, row['html_content'])\n","    screenshot_path = os.path.join(base_path, row['screenshot'])\n","\n","    # Read HTML content\n","    with open(html_path, 'r', encoding='utf-8') as file:\n","        html_content = file.read()\n","\n","    # Load and prepare image\n","    screenshot = Image.open(screenshot_path).convert('RGB')\n","    if screenshot is None:\n","        raise ValueError(f\"Could not load the image: {screenshot_path}\")\n","    screenshot = screenshot.resize((512, 512))  # Resize\n","\n","    return html_content, screenshot"],"metadata":{"id":"M7001btqR4iP","executionInfo":{"status":"ok","timestamp":1758457951599,"user_tz":-120,"elapsed":5,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"M7001btqR4iP","execution_count":24,"outputs":[]},{"cell_type":"code","source":["def _generate_response(model, messages, processor, screenshot):\n","    \"\"\"\n","    Generates a response from a multi-modal model based on a list of messages and an image.\n","\n","    Args:\n","        model: The multi-modal model instance.\n","        messages (list): A list of dictionaries representing the chat history.\n","        processor: The processor for the model (tokenization and image processing).\n","        screenshot: A PIL Image object of the screenshot.\n","\n","    Returns:\n","        str: The generated text response from the model.\n","\n","    Raises:\n","        Exception: If an error occurs during the generation process.\n","    \"\"\"\n","    try:\n","        # 1. Apply the chat template\n","        # This converts the `messages` list of dictionaries into a single string\n","        # that the model expects as input.\n","        prompt = processor.tokenizer.apply_chat_template(\n","            messages,\n","            tokenize=False,\n","            add_generation_prompt=True\n","        )\n","\n","        # 2. Process the prompt and image to get the inputs\n","        # The processor takes the text and image separately.\n","        inputs = processor(\n","            text=prompt,\n","            images=[screenshot],  # This line can be removed if you only want to analyze text.\n","            return_tensors=\"pt\"\n","        ).to(model.device)\n","\n","        # 3. Generate the response\n","        generation_args = {\n","            \"max_new_tokens\": 512,  # You can adjust this\n","            \"temperature\": 0.0,\n","            \"do_sample\": False,\n","        }\n","\n","        generate_ids = model.generate(\n","            **inputs,\n","            eos_token_id=processor.tokenizer.eos_token_id,\n","            **generation_args\n","        )\n","\n","        # 4. Decode the response\n","        # We only decode the tokens generated by the model, not the input tokens.\n","        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n","        response = processor.batch_decode(\n","            generate_ids,\n","            skip_special_tokens=True,\n","            clean_up_tokenization_spaces=False\n","        )[0]\n","\n","        return response\n","\n","    except Exception as e:\n","        print(f\"❌ Error generating response: {type(e).__name__} - {e}\")\n","        return f\"Error: {type(e).__name__} - {e}\""],"metadata":{"id":"Z-mzoum0RECf","executionInfo":{"status":"ok","timestamp":1758457951605,"user_tz":-120,"elapsed":3,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"Z-mzoum0RECf","execution_count":25,"outputs":[]},{"cell_type":"code","source":["def _configure_model(model_id: str):\n","    \"\"\"\n","    Configures and loads a language model and its processor for inference.\n","\n","    Args:\n","        model_id (str): The identifier of the model to load (e.g., 'qwen/Qwen-VL').\n","\n","    Returns:\n","        tuple: A tuple containing the loaded model, its processor, and the configuration.\n","\n","    Raises:\n","        ValueError: If the provided model_id is not found in the configuration dictionary.\n","    \"\"\"\n","    print(f\"⚡ Configuring and loading pipeline for {model_id}...\")\n","\n","    torch.cuda.empty_cache()\n","\n","    # Load the model from a pre-trained checkpoint\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_id,\n","        device_map=\"cuda\",\n","        trust_remote_code=True,\n","        torch_dtype=\"auto\",\n","        attn_implementation='flash_attention_2'\n","    )\n","\n","    # Load the processor (tokenizer and image processor)\n","    processor = AutoProcessor.from_pretrained(\n","        model_id,\n","        trust_remote_code=True,\n","        num_crops=4\n","    )\n","\n","    return model, processor"],"metadata":{"id":"2-PQGxiRPO6-","executionInfo":{"status":"ok","timestamp":1758457985534,"user_tz":-120,"elapsed":28,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"2-PQGxiRPO6-","execution_count":30,"outputs":[]},{"cell_type":"code","source":["def _process_row(row: pd.Series, model, processor, base_path: str, output_filepath: str, prompt_method_to_use):\n","    \"\"\"\n","    Processes a single row from the DataFrame: loads data, builds the prompt, and generates a response.\n","\n","    Args:\n","        row (pd.Series): The row of the DataFrame to process.\n","        model: The loaded language model.\n","        processor: The model's processor (tokenizer, image processor).\n","        base_path (str): The base directory for data files.\n","        output_filepath (str): The path to the output log file.\n","        prompt_method_to_use: The function to use for building the prompt.\n","\n","    Returns:\n","        str: The generated text response from the model, or an error message.\n","    \"\"\"\n","    url = row.get('url', 'URL unknown')\n","    label = row.get('label', 'Label unknown')\n","    label_text = \"PHISHING (true)\" if label == 1 else \"SAFE (false)\"\n","    try:\n","        # 1. Load data\n","        html_content, screenshot = _load_row_data(row, base_path)\n","\n","        # 2. Build prompt\n","        messages = prompt_method_to_use(html_content, screenshot, url)\n","\n","        # 3. Generate Response\n","        generated_text = _generate_response(model, messages, processor, screenshot)\n","\n","        # 4. Log output\n","        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","        print(f\"--- FULL Output for URL: {url} {label_text} ({timestamp}) ---\")\n","        print(generated_text)\n","        print(f\"--- End of Full Output ---\")\n","\n","        try:\n","            # Open the file in append mode ('a') with utf-8 encoding\n","            with open(output_filepath, 'a', encoding='utf-8') as f:\n","                f.write(f\"URL: {url}\\n\")\n","                f.write(f\"\\nExpected Result: {label_text}\\n\")\n","                f.write(f\"Output: {generated_text}\\n\\n\")\n","        except IOError as e:\n","            print(f\"❌ Error writing to file {output_filepath} for {url}: {e}\")\n","\n","        # 5. Return the result for the 'prediction' column\n","        # (Consider if you need to parse the XML here or later)\n","        return generated_text\n","\n","    except FileNotFoundError as e:\n","        print(f\"❌ Error - File not found for {url}: {e}\")\n","        return f\"Error: File not found ({e.filename})\"\n","    except ValueError as e:\n","        print(f\"❌ Error - Invalid value (e.g., image loading) for {url}: {e}\")\n","        return f\"Error: {e}\"\n","    except Exception as e:\n","        # Generic catch for other unexpected errors during row processing\n","        print(f\"❌ Unexpected error processing {url}: {type(e).__name__} - {e}\")\n","        return \"Analysis Error\""],"metadata":{"id":"cs-FIEqBQzEs","executionInfo":{"status":"ok","timestamp":1758458156699,"user_tz":-120,"elapsed":14,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"cs-FIEqBQzEs","execution_count":35,"outputs":[]},{"cell_type":"code","source":["def classifier(model_id: str, df: pd.DataFrame, base_path: str, output_filepath: str, prompt_method_to_use):\n","    \"\"\"\n","    Main function to classify a DataFrame using a specified model and prompting method.\n","\n","    Args:\n","        model_id (str): Identifier for the model to use.\n","        df (pd.DataFrame): The DataFrame containing the data to classify.\n","        base_path (str): The base directory for data files.\n","        output_filepath (str): The path to the output log file.\n","        prompt_method_to_use: The function to use for building the prompt.\n","\n","    Returns:\n","        pd.DataFrame: The original DataFrame with a new 'prediction' column.\n","    \"\"\"\n","    model = None\n","    processor = None\n","\n","    try:\n","        # 1. Configure and load the model\n","        model, processor = _configure_model(model_id)\n","\n","        # 2. Create a partial function to pass fixed arguments to the processing function\n","        process_row_with_context = partial(\n","            _process_row,\n","            model=model,\n","            processor=processor,\n","            base_path=base_path,\n","            output_filepath=output_filepath,\n","            prompt_method_to_use=prompt_method_to_use\n","        )\n","\n","        # 3. Apply the processing function to the entire DataFrame\n","        print(f\"🚀 Processing {len(df)} rows...\")\n","        df['prediction'] = df.apply(process_row_with_context, axis=1)\n","        print(\"✅ Processing completed.\")\n","        return df\n","\n","    except ValueError as e:\n","        # Handle errors during pipeline configuration\n","        print(f\"❌ Critical Error - Configuration failed: {e}\", file=sys.stderr)\n","        return df\n","    except Exception as e:\n","        # Handle other unexpected errors (e.g., CUDA memory error when loading the model)\n","        print(f\"❌ Unexpected Critical Error: {type(e).__name__} - {e}\", file=sys.stderr)\n","        return df\n","    finally:\n","        # Release memory in a final block to ensure it always runs\n","        if model is not None:\n","            print(f\"🧹 Releasing model '{model_id}'...\")\n","            del model\n","            print(\"✅ Model released.\")\n","\n","        # Clear CUDA cache to free up GPU memory\n","        print(\"🗑️ Clearing CUDA cache...\")\n","        torch.cuda.empty_cache()\n","        print(\"✅ CUDA cache cleared.\")\n","\n","        # Note: The code had two identical `finally` blocks for clearing the cache.\n","        # I've kept the logic in a single, more efficient `finally` block."],"metadata":{"id":"8RDsAw6POtGV","executionInfo":{"status":"ok","timestamp":1758458154700,"user_tz":-120,"elapsed":8,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}}},"id":"8RDsAw6POtGV","execution_count":34,"outputs":[]},{"cell_type":"code","source":[" selected_model = 'microsoft/Phi-3.5-vision-instruct'\n","\n","prompt_methods1 = [\n","    prompt_option1_all,\n","    prompt_option2_all,\n","    prompt_option3_all,\n","    prompt_option1_screenshot,\n","    prompt_option2_screenshot,\n","    prompt_option3_screenshot\n","]\n","\n","prompt_methods2 = [\n","    prompt_option1_url,\n","    prompt_option2_url,\n","    prompt_option3_url,\n","    prompt_option1_html,\n","    prompt_option2_html,\n","    prompt_option3_html\n","]\n","\n","# Paths and data\n","files_path = '/content/drive/MyDrive/Colab Notebooks/DatasetV1'\n","files_path = os.path.join(files_path, '')\n","csv_path = '/content/drive/MyDrive/Colab Notebooks/DatasetV1/datasetV1.csv'\n","df_data = pd.read_csv(csv_path, encoding='utf-8')\n","output_directory_path = '/content/drive/MyDrive/Colab Notebooks'\n","\n","\n","print(f\"\\n===== Processing Model: {selected_model} =====\")\n","base_filename = selected_model.split('/')[-1]\n","\n","# Inner loop: Iterate over each prompt method\n","for i, prompt_method in enumerate(prompt_methods1):\n","    method_name = prompt_method.__name__\n","\n","    # Generate a unique filename for each model and method combination\n","    output_filename = f\"{base_filename}_{method_name}_results.txt\"\n","    final_output_filepath = os.path.join(output_directory_path, output_filename)\n","\n","    print(f\"  --- Executing with method: {method_name} ---\")\n","    print(f\"  Saving results to: {final_output_filepath}\")\n","\n","    # Call the classifier function with the new filename\n","    # and pass the prompt method to be used internally\n","    df_result = classifier(\n","        model_id=selected_model,\n","        df=df_data,\n","        base_path=files_path,\n","        output_filepath=final_output_filepath,\n","        prompt_method_to_use=prompt_method\n","    )\n","    print(\"--------------------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["db52861d4c42425aaf1459a002e9d5b2","11743b0429b247248c52fda333d04987","146eb2d117254ed9b82b72fa813d6f5a","ab68b2e0d856442a803d5c3d9a5613c3","54e32c0af3a94cca8e74d191cd325b41","1d5bc5b4342e403280f13b6ad405ce70","a87640e502504d06a23eaa7f9216296d","fea80282b57e4d08b0264be5bb49cb61","ea7a80faa54b4b259c759bda39a74393","5481a0ea437b47af81db73c47c5bddd8","09b0d7d8819d49208f194b59082ed312"]},"id":"Kso-y6uVxy3u","executionInfo":{"status":"error","timestamp":1758458187698,"user_tz":-120,"elapsed":21385,"user":{"displayName":"Álvaro López Fueyo","userId":"16218750490699688205"}},"outputId":"b104b460-05be-48b8-f339-3c4b5cefda6c"},"id":"Kso-y6uVxy3u","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Processing Model: microsoft/Phi-3.5-vision-instruct =====\n","  --- Executing with method: prompt_option1_all ---\n","  Saving results to: /content/drive/MyDrive/Colab Notebooks/Phi-3.5-vision-instruct_prompt_option1_all_results.txt\n","⚡ Configuring and loading pipeline for microsoft/Phi-3.5-vision-instruct...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db52861d4c42425aaf1459a002e9d5b2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["🚀 Processing 1000 rows...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n","`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"]},{"output_type":"stream","name":"stdout","text":["--- FULL Output for URL: http://bafybeicq2uxnud6qz2nlla7utndhtjtrugydx3tdzhjzj7zjx4jbffigie.ipfs.infura-ipfs.io PHISHING (true) (2025-09-21 12:36:14) ---\n","Phishing\n","--- End of Full Output ---\n","--- FULL Output for URL: http://bafybeiddrvh2jskkihnnlw4i4rs23m43bg56bjpdr43cfon6oddmha6lue.ipfs.dweb.link PHISHING (true) (2025-09-21 12:36:16) ---\n","Phishing\n","--- End of Full Output ---\n","--- FULL Output for URL: http://bafybeiddup6lnmz2bs3ywtoo7ygy7nuxzppsgqtuyzw54fpqryvosoumvu.ipfs.dweb.link PHISHING (true) (2025-09-21 12:36:17) ---\n","Legitimate\n","--- End of Full Output ---\n","--- FULL Output for URL: http://01anjali2001.github.io/netflix PHISHING (true) (2025-09-21 12:36:20) ---\n","Legitimate\n","--- End of Full Output ---\n","--- FULL Output for URL: http://bafybeidoglaizl6f2nvlkf3n7aek4appfd4goj5a5fovzmg52vaa2wcggu.ipfs.dweb.link PHISHING (true) (2025-09-21 12:36:22) ---\n","Phishing\n","--- End of Full Output ---\n","--- FULL Output for URL: http://bafybeidmsq7bsjz7mqcekzwnicnbh2b2bptwpbvqftmwtajg32kmjk7kzy.ipfs.dweb.link PHISHING (true) (2025-09-21 12:36:23) ---\n","Phishing\n","--- End of Full Output ---\n","--- FULL Output for URL: http://023traff4hugedomains.weebly.com PHISHING (true) (2025-09-21 12:36:25) ---\n","Phishing\n","--- End of Full Output ---\n","🧹 Releasing model 'microsoft/Phi-3.5-vision-instruct'...\n","✅ Model released.\n","🗑️ Clearing CUDA cache...\n","✅ CUDA cache cleared.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-152080078.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m    \u001b[0;31m# Call the classifier function with the new filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m    \u001b[0;31m# and pass the prompt method to be used internally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m    df_result = classifier(\n\u001b[0m\u001b[1;32m     46\u001b[0m        \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselected_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m        \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1721484481.py\u001b[0m in \u001b[0;36mclassifier\u001b[0;34m(model_id, df, base_path, output_filepath, prompt_method_to_use)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# 3. Apply the processing function to the entire DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"🚀 Processing {len(df)} rows...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_row_with_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Processing completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2801321791.py\u001b[0m in \u001b[0;36m_process_row\u001b[0;34m(row, model, processor, base_path, output_filepath, prompt_method_to_use)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 3. Generate Response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreenshot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 4. Log output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1928478885.py\u001b[0m in \u001b[0;36m_generate_response\u001b[0;34m(model, messages, processor, screenshot)\u001b[0m\n\u001b[1;32m     40\u001b[0m         }\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         generate_ids = model.generate(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3.5-vision-instruct/4a0d683eba9f1d0cbfb6151705d1ee73c25a80ca/modeling_phi3_v.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, image_sizes, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1604\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3.5-vision-instruct/4a0d683eba9f1d0cbfb6151705d1ee73c25a80ca/modeling_phi3_v.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, image_sizes, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                 )\n\u001b[1;32m   1478\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1480\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3.5-vision-instruct/4a0d683eba9f1d0cbfb6151705d1ee73c25a80ca/modeling_phi3_v.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         attn_outputs, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3.5-vision-instruct/4a0d683eba9f1d0cbfb6151705d1ee73c25a80ca/modeling_phi3_v.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Because the input can be padded, the absolute sequence length depends on the max position id.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mrotary_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkv_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrotary_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"db52861d4c42425aaf1459a002e9d5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11743b0429b247248c52fda333d04987","IPY_MODEL_146eb2d117254ed9b82b72fa813d6f5a","IPY_MODEL_ab68b2e0d856442a803d5c3d9a5613c3"],"layout":"IPY_MODEL_54e32c0af3a94cca8e74d191cd325b41"}},"11743b0429b247248c52fda333d04987":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d5bc5b4342e403280f13b6ad405ce70","placeholder":"​","style":"IPY_MODEL_a87640e502504d06a23eaa7f9216296d","value":"Loading checkpoint shards: 100%"}},"146eb2d117254ed9b82b72fa813d6f5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fea80282b57e4d08b0264be5bb49cb61","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea7a80faa54b4b259c759bda39a74393","value":2}},"ab68b2e0d856442a803d5c3d9a5613c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5481a0ea437b47af81db73c47c5bddd8","placeholder":"​","style":"IPY_MODEL_09b0d7d8819d49208f194b59082ed312","value":" 2/2 [00:03&lt;00:00,  1.54s/it]"}},"54e32c0af3a94cca8e74d191cd325b41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d5bc5b4342e403280f13b6ad405ce70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a87640e502504d06a23eaa7f9216296d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fea80282b57e4d08b0264be5bb49cb61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea7a80faa54b4b259c759bda39a74393":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5481a0ea437b47af81db73c47c5bddd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b0d7d8819d49208f194b59082ed312":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}